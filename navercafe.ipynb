{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pyperclip\n",
    "import random\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#크롬 웹 드라이버의 경로 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  # 브라우저 숨기기\n",
    "driver = webdriver.Chrome('C:\\chromedriver.exe', chrome_options=options)\n",
    "\n",
    "# 네이버 로그인 페이지 접속\n",
    "driver.get(\"https://nid.naver.com/nidlogin.login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그인 정보\n",
    "login = {\"id\" : \"chaton59\", \"pw\" : \"beauty5900\"}\n",
    "\n",
    "# 로그인 정보 입력 함수\n",
    "def clipboard_input(user_xpath, user_input):\n",
    "    temp_user_input = pyperclip.paste()\n",
    "\n",
    "    pyperclip.copy(user_input)\n",
    "    driver.find_element_by_xpath(user_xpath).click()\n",
    "    ActionChains(driver).key_down(Keys.CONTROL).send_keys('v').key_up(Keys.CONTROL).perform()\n",
    "\n",
    "    pyperclip.copy(temp_user_input)\n",
    "    time.sleep(1)\n",
    "\n",
    "# id, pw 입력 후 클릭\n",
    "clipboard_input('//*[@id=\"id\"]', login.get(\"id\"))\n",
    "clipboard_input('//*[@id=\"pw\"]', login.get(\"pw\"))\n",
    "driver.find_element_by_xpath('//*[@id=\"log.login\"]').click()\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장 경로\n",
    "save_path = \"C:\\jupiter_workspace\\zam_project\\outputs\"\n",
    "\n",
    "# 카페 정보\n",
    "cafe = {'name': '대구맘365','page_link': 'https://cafe.naver.com/dgmom365'}\n",
    "cafe.update({\"keywords\" : [\"기저귀\"]})         # 검색 키워드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카페 게시글 링크 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(현재시각) 2022-05-12 10:41:53.798953: 1page done\n",
      "(현재시각) 2022-05-12 10:41:57.622437: 2page done\n"
     ]
    }
   ],
   "source": [
    "for keyword in cafe.get(\"keywords\"):\n",
    "    ### 카페 주소 입력\n",
    "    driver.get(cafe.get(\"page_link\"))\n",
    "    \n",
    "    ### 키워드 검색\n",
    "    clipboard_input('//*[@id=\"topLayerQueryInput\"]', keyword)\n",
    "    try :\n",
    "        driver.find_element_by_xpath('//*[@id=\"cafe-search\"]/form/button').click()   # 왼쪽에 검색창\n",
    "    except:\n",
    "        driver.find_element_by_xpath('//*[@id=\"info-search\"]/form/button').click()   # 오른쪽에 검색창\n",
    "    driver.implicitly_wait(0.5)\n",
    "    driver.switch_to.frame('cafe_main')\n",
    "\n",
    "    ### 키워드 수집 정보\n",
    "    num_per_page = 15          # 페이지당 게시글 갯수(default: 15개)\n",
    "\n",
    "    address_list=[]\n",
    "    #address_df = pd.DataFrame(columns=['no'])\n",
    "    page = 1\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        time.sleep( random.randint(0,5) )\n",
    "        \n",
    "        ### 현재 페이지의 html 불러오기\n",
    "        r = driver.page_source\n",
    "        page_html = BeautifulSoup(r, \"html.parser\")\n",
    "        content = page_html.find(\"div\", class_=\"article-board result-board m-tcol-c\").find('tbody')\n",
    "#         content = page_html.find_all(\"div\", class_=\"article-board m-tcol-c\")[1].find('tbody')\n",
    "        body = content.find_all(\"tr\")\n",
    "\n",
    "        ### 게시글 정보 저장하기\n",
    "        for x in body:\n",
    "            temp_dict={}\n",
    "            if x.find(\"div\", class_=\"board-number\") is not None:\n",
    "                temp_dict['no'] = x.find(\"div\", class_=\"board-number\").text.strip()\n",
    "                temp_dict['title'] = x.find(\"div\", class_=\"board-list\").text.strip().replace('  ','').replace('\\n','')\n",
    "                temp_dict['link'] = x.find('a').get('href')\n",
    "                temp_dict['name'] = x.find(\"td\", class_=\"td_name\").find('a',class_='m-tcol-c').text.strip()\n",
    "                temp_dict['date'] = x.find(\"td\", class_=\"td_date\").text.strip()\n",
    "                temp_dict['view'] = x.find(\"td\", class_=\"td_view\").text.strip()\n",
    "                address_list.append(temp_dict)\n",
    "        print(\"(현재시각) \"+str(datetime.datetime.now())+\": \"+ str(page) +\"page done\")\n",
    "\n",
    "        ### 다음 페이지로 넘어가기\n",
    "        page+=1\n",
    "        driver.implicitly_wait(1)\n",
    "        \n",
    "        try:\n",
    "            if page<=10:   # 1~10 : 페이지 번호 그대로\n",
    "                page_xpath = str(page)\n",
    "                driver.find_element_by_xpath('//*[@id=\"main-area\"]/div[7]/a[' + page_xpath + ']').click()\n",
    "            elif page == 11:   # 11 : 다음 버튼\n",
    "                driver.find_element_by_xpath('//*[@id=\"main-area\"]/div[7]/a[11]/span').click()\n",
    "            elif page>11 and page%10!=1:   # 12~ : 페이지 번호 마지막 자리 + 1\n",
    "                page_xpath = str(page-((page-1)//10)*10+1)\n",
    "                driver.find_element_by_xpath('//*[@id=\"main-area\"]/div[7]/a[' + page_xpath + ']').click()\n",
    "            elif page%10 == 1:   # 21,31.. : 다음 버튼\n",
    "                driver.find_element_by_xpath('//*[@id=\"main-area\"]/div[7]/a[12]/span').click()\n",
    "        except:\n",
    "                print(\"(현재시각) \"+str(datetime.datetime.now())+\": done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(현재시각) 2022-05-12 10:42:00.507173: done\n",
      "검색게시글수 :  (30, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>view</th>\n",
       "      <th>idx_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5840389</td>\n",
       "      <td>[판매중]구찌 백( 정품)판매사진new개인거래(판매), 판매중, 가격 230,000...</td>\n",
       "      <td>/ca-fe/ArticleRead.nhn?clubid=24000254&amp;page=1&amp;...</td>\n",
       "      <td>옥포v달비채</td>\n",
       "      <td>09:41</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5840223</td>\n",
       "      <td>자면서 응가ㅡㅡㅡ[6]new이런적은 처음인데요ㅡㅡ 방금 기저귀갈면서 보니.악!응가를...</td>\n",
       "      <td>/ca-fe/ArticleRead.nhn?clubid=24000254&amp;page=1&amp;...</td>\n",
       "      <td>월성새내기</td>\n",
       "      <td>05:02</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5840003</td>\n",
       "      <td>성서에 요로감염 병원찾아요[6]new아기가 열은 안나는데 기저귀에 콧물처럼 이물질이...</td>\n",
       "      <td>/ca-fe/ArticleRead.nhn?clubid=24000254&amp;page=1&amp;...</td>\n",
       "      <td>이곡융</td>\n",
       "      <td>2022.05.11.</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5839885</td>\n",
       "      <td>영아수당 신청 달바껴서 신청하면요~(+기저귀바우처)[6]new지난달 출산해서 조리원...</td>\n",
       "      <td>/ca-fe/ArticleRead.nhn?clubid=24000254&amp;page=1&amp;...</td>\n",
       "      <td>딩가v북구</td>\n",
       "      <td>2022.05.11.</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5839744</td>\n",
       "      <td>맘님들이라면 어쩌시겠어요?[7]new오늘 아침에 아기 기저귀 갈다가 사타구니쪽이 볼...</td>\n",
       "      <td>/ca-fe/ArticleRead.nhn?clubid=24000254&amp;page=1&amp;...</td>\n",
       "      <td>혁신쑥쑥맘89</td>\n",
       "      <td>2022.05.11.</td>\n",
       "      <td>499</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        no                                              title  \\\n",
       "0  5840389  [판매중]구찌 백( 정품)판매사진new개인거래(판매), 판매중, 가격 230,000...   \n",
       "1  5840223  자면서 응가ㅡㅡㅡ[6]new이런적은 처음인데요ㅡㅡ 방금 기저귀갈면서 보니.악!응가를...   \n",
       "2  5840003  성서에 요로감염 병원찾아요[6]new아기가 열은 안나는데 기저귀에 콧물처럼 이물질이...   \n",
       "3  5839885  영아수당 신청 달바껴서 신청하면요~(+기저귀바우처)[6]new지난달 출산해서 조리원...   \n",
       "4  5839744  맘님들이라면 어쩌시겠어요?[7]new오늘 아침에 아기 기저귀 갈다가 사타구니쪽이 볼...   \n",
       "\n",
       "                                                link     name         date  \\\n",
       "0  /ca-fe/ArticleRead.nhn?clubid=24000254&page=1&...   옥포v달비채        09:41   \n",
       "1  /ca-fe/ArticleRead.nhn?clubid=24000254&page=1&...    월성새내기        05:02   \n",
       "2  /ca-fe/ArticleRead.nhn?clubid=24000254&page=1&...      이곡융  2022.05.11.   \n",
       "3  /ca-fe/ArticleRead.nhn?clubid=24000254&page=1&...    딩가v북구  2022.05.11.   \n",
       "4  /ca-fe/ArticleRead.nhn?clubid=24000254&page=1&...  혁신쑥쑥맘89  2022.05.11.   \n",
       "\n",
       "  view  idx_no  \n",
       "0  133       1  \n",
       "1  327       2  \n",
       "2  103       3  \n",
       "3  111       4  \n",
       "4  499       5  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_df = pd.DataFrame(address_list)\n",
    "address_df['idx_no'] = range(1,len(address_df)+1)   # 조인할 키 값\n",
    "address_df.to_pickle(save_path+\"cafe_address_\"+cafe.get(\"name\")+\"_\"+keyword+\".pkl\")\n",
    "print(\"(현재시각) \"+str(datetime.datetime.now())+\": done\")\n",
    "\n",
    "if len(set(address_df['no']))!=len(address_df) :\n",
    "    print(\"게시글 번호에 중복 존재\")\n",
    "print(\"검색게시글수 : \", address_df.shape)\n",
    "\n",
    "address_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(현재시각) 2022-05-12 10:46:01.420271: done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from contextlib import suppress\n",
    "\n",
    "for keyword in cafe.get(\"keywords\"):\n",
    "    df = pickle.load(open(save_path+\"cafe_address_\"+cafe.get(\"name\")+\"_\"+keyword+\".pkl\", 'rb'))\n",
    "\n",
    "    i=0\n",
    "    contents_list = []   # 내용\n",
    "    reply_list = []      # 댓글\n",
    "    error_list = []      # 에러난 게시글\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ### 수집 링크로 이동\n",
    "        url = \"https://cafe.naver.com\"+df.loc[i,'link']\n",
    "        idx_no = df.loc[i,'idx_no']    # 인덱스 번호\n",
    "        driver.get(url)\n",
    "        time.sleep( random.randint(2,5) )\n",
    "        try:\n",
    "            driver.switch_to.frame('cafe_main')\n",
    "            time.sleep( random.randint(2,5) )\n",
    "            r = driver.page_source\n",
    "            page_soup = BeautifulSoup(r, \"html.parser\")\n",
    "            content = page_soup.find('div', class_='ArticleContentBox')  \n",
    "\n",
    "            ### 게시글 수집\n",
    "            temp_dict={}\n",
    "            temp_dict['idx_no'] = idx_no\n",
    "            temp_dict['title'] = \"\"\n",
    "            with suppress(AttributeError):   # 제목 없는 게시글\n",
    "                temp_dict['title'] = content.find('h3',class_='title_text').text.strip()\n",
    "            temp_dict['content'] = content.find(\"div\", class_=\"article_viewer\").text.strip()\n",
    "            temp_dict['nick'] = content.find('div',class_='profile_info').find('a',class_='nickname').text.strip()\n",
    "            temp_dict['date'] = content.find('div',class_='article_info').find('span',class_='date').text.strip()\n",
    "            temp_dict['view'] = \"\"\n",
    "            with suppress(AttributeError):\n",
    "                temp_dict['view'] = content.find('div',class_='article_info').find('span',class_='count').text.strip()\n",
    "            contents_list.append(temp_dict)\n",
    "\n",
    "            ### 댓글 수집\n",
    "            if content.find(\"div\", class_=\"ReplyBox\") is not None:   # 댓글 기능이 아예 없음  \n",
    "                comment_num = content.find(\"div\", class_=\"ReplyBox\").find(\"a\",class_=\"button_comment\").find(\"strong\").text\n",
    "                if comment_num!='0':   # 댓글이 없음\n",
    "                    comment = content.find(\"div\", class_=\"CommentBox\").find(\"ul\",class_=\"comment_list\").select(\"li\")\n",
    "                    \n",
    "                    ### 댓글 구분\n",
    "                    com_n=0    # 댓글\n",
    "                    com_nn=0   # 대댓글\n",
    "                    \n",
    "                    for n in range(len(comment)):\n",
    "\n",
    "                        if comment[n].get('class')==['CommentItem']:    # 댓글\n",
    "                            com_n+=1; com_nn=0;\n",
    "                            com_thread = str(com_n)+\"-\"+str(com_nn)\n",
    "                            com_nn=1\n",
    "                        elif comment[n].get('class')==['CommentItem', 'CommentItem--reply']:    # 대댓글\n",
    "                            com_thread = str(com_n)+\"-\"+str(com_nn)\n",
    "                            com_nn+=1\n",
    "\n",
    "                        ### 댓글 내용 수집    \n",
    "                        if comment[n].text.strip() != '삭제된 댓글입니다.':\n",
    "                            com_nick = comment[n].find(\"a\",class_=\"comment_nickname\").text.strip()\n",
    "                            com_date = comment[n].find(\"span\",class_=\"comment_info_date\").text.strip()\n",
    "                            com_reply = comment[n].find(\"div\",class_=\"comment_text_box\").text.strip()\n",
    "                            reply_list.append({'idx_no':idx_no, 'nick':com_nick, 'date':com_date, 'reply':com_reply, \"thread\":com_thread})\n",
    "            i+=1\n",
    "\n",
    "        except:\n",
    "            i+=1\n",
    "            ### 게시글을 볼 등급이 안됨\n",
    "            if page_soup.find('strong', class_='emph') is not None:\n",
    "                error_list.append({\"error\" :  page_soup.find('strong', class_='emph').text+\"등급 필요\", \"url\" : url})\n",
    "                pass\n",
    "            ### 에러 따로 확인\n",
    "            else:\n",
    "                error_list.append({\"error\" : \"에러 확인 필요\", \"url\" : url})\n",
    "                pass\n",
    "\n",
    "        ### 수집한 글 갯수만큼 반복\n",
    "        if i == len(df):\n",
    "            contents_df = pd.DataFrame(contents_list)\n",
    "            contents_df.to_pickle(\"C:\\jupiter_workspace\\zam_project\\outputs/cafe_\"+cafe.get(\"name\")+\"_\"+keyword+\".pkl\")\n",
    "            reply_df = pd.DataFrame(reply_list)\n",
    "            reply_df.to_pickle(\"C:\\jupiter_workspace\\zam_project\\outputs/cafe_replies_\"+cafe.get(\"name\")+\"_\"+keyword+\".pkl\")\n",
    "            print(\"(현재시각) \"+str(datetime.datetime.now())+\": done\")\n",
    "            break\n",
    "    \n",
    "# 크롬 종료 \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9792/2858132371.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'comment' is not defined"
     ]
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수집 데이터 :  (0, 0)\n",
      "에러 게시글 수 :  30\n"
     ]
    }
   ],
   "source": [
    "# 수집한 데이터 : contents_df\n",
    "print(\"수집 데이터 : \", contents_df.shape)\n",
    "# 에러 난 게시글 : error_list\n",
    "print(\"에러 게시글 수 : \", len(error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
